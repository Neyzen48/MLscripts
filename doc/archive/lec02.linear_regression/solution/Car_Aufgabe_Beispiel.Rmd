---
title: "Linear_regression_KERAS"
author: "Dr. Houssam Jedidi"
date: "`r Sys.Date()`"
output: html_document
---

# 1 Einführung

In einem Regressionsproblem liegt der Fokus darauf, die Ausgabe eines kontinuierlichen Werts vorherzusagen, wie beispielsweise einen Preis oder eine Wahrscheinlichkeit. Im Gegensatz dazu besteht bei einem Klassifikationsproblem das Ziel darin, eine Klasse aus einer Liste von Klassen auszuwählen (zum Beispiel, ob ein Bild einen Apfel oder eine Orange enthält und zu erkennen, welche Frucht auf dem Bild zu sehen ist).

Dieses Tutorial verwendet den klassischen Auto MPG-Datensatz und zeigt, wie Modelle erstellt werden, um die Kraftstoffeffizienz von Autos aus den späten 1970er und frühen 1980er Jahren vorherzusagen. Dafür werden den Modellen Beschreibungen vieler Autos aus dieser Zeit zur Verfügung gestellt. Diese Beschreibungen enthalten Attribute wie Zylinderzahl, Hubraum, Pferdestärken und Gewicht.

# 2 Packages
```{r}
#install.packages("mice")
```

# 3 Libraries
```{r, warning=FALSE, include=FALSE}
library(dplyr) # wrangling
library(tidyverse)
library(magrittr) # piping %>% 
library(tibble)
# ML libraries
library(rpart) # Entscheiungbaumregression
library(randomForest)
library(tidymodels)
library(caret)
# Plotting
library(ggplot2)
# reading files
library(readr)
# EDA
library(correlationfunnel) 
library(skimr)
library(DataExplorer)
# imputation
library(mice) 
# Recipe (Workflow)
library(recipes) 
```

# 4 Datensatz
```{r, warning=FALSE, include=FALSE}
# url <- "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
# col_names <- c("mpg","cylinders","displacement","horsepower","weight","acceleration","model_year", "origin","car_name")
# 
# raw_dataset <- read.table(
#   url,
#   header = T,
#   col.names = col_names,
#   na.strings = "?"
# )
# write_csv(raw_dataset,"Data/Sample_car_dataset.csv")

Sample_car_dataset<- read_csv("Data/Sample_car_dataset.csv")
```

```{r, warning=FALSE}
head(Sample_car_dataset,10)
```

# 5 EDA
```{r}
Sample_car_dataset %>% skim()
Sample_car_dataset %>% plot_missing()
```
# Mögliches Wrangling 
```{r}
# check für dopplungen

cleaned_data<- Sample_car_dataset %>% 
  unique()
# Löscht NA egal wo in der Zeile
data_without_NA<- Sample_car_dataset %>% 
  na.omit()

# Löschen NA nur in der Spalte Horsepower
data_HP_without_NA<- Sample_car_dataset %>% 
  filter(!is.na(horsepower))

```



Wir merken dass bei 6 Autos die P-Stärke fehlt --> lets practice imputation

PMM steht für "Predictive Mean Matching" und ist eine Methode zur Imputation von fehlenden Werten in statistischen Analysen, insbesondere in multivariaten Datensätzen. PMM ist eine Methode, die auf dem Konzept der Vorhersage basiert, indem der fehlende Wert durch den gematchten vorhergesagten Mittelwert eines ähnlichen Datensatzes ersetzt wird.

Im Kontext der mice-Funktion in R, die für multiple Imputation von fehlenden Daten verwendet wird, steht PMM für eine der verfügbaren Imputationsmethoden. Wenn Sie method = "pmm" in der mice-Funktion verwenden, werden die fehlenden Werte durch vorhergesagte Mittelwerte aus einer Verteilung von Werten ersetzt, die auf den vorhandenen Daten basiert.

Der PMM-Algorithmus in mice funktioniert, indem er für jeden fehlenden Wert einen imputeden Wert auswählt, der so nah wie möglich zum ursprünglichen Wert liegt. Dies erfolgt durch Vorhersage eines Regressionsmodells für die Variable mit fehlenden Werten unter Verwendung der anderen Variablen im Datensatz und Auswahl des am besten passenden gematchten Werts.

Andere Möglichkeiten: "logreg", "polyreg", "polr","lasso.norm, etc.
```{r, include=FALSE}
imputed_data <- mice(Sample_car_dataset, m =5, maxit = 10, method = "pmm")

# Zusammenführung der imputierten Daten
imputed_df <- complete(imputed_data) %>% 
  as.data.frame()
  #as.tibble()
```

```{r}
imputed_df %>% plot_missing()
```
 Nun ist unser Datensatz vollständig und wir Können das ML-workflow starten
 
 # 6 Splitting Datensatz für ML
```{r, warning=FALSE,include=FALSE}
# Split in Train und Test Sets
set.seed(123)
split_data <- initial_split(imputed_df, prop = 0.7)
train_data <- training(split_data)
test_data <- testing(split_data)


```

# 7 Erstellen eines Rezepts
Ein Rezept (recipe) in R, insbesondere im Kontext von maschinellem Lernen, ist eine Spezifikation von Daten-Transformations- und -Vorbereitungsstufen. Es definiert, wie die Daten vor dem Einsatz in einem Modell behandelt werden sollen. Ein Rezept kann Schritte wie Normalisierung, Imputation fehlender Werte, Dummy-Variablen-Erstellung für kategoriale Variablen und andere Transformationen enthalten.

step_rm(car_name): Entfernt die Variable "car_name" aus dem Rezept.
step_normalize(all_numeric_predictors()): Normalisiert alle numerischen Prädiktoren im Rezept.
step_dummy(all_nominal_predictors(), -all_outcomes()): Erstellt Dummy-Variablen für alle kategorialen Prädiktoren im Rezept (außer der abhängigen Variable).
prep(my_recipe_without_car_name, training = train_data): Bereitet das Rezept vor, indem es auf den Trainingsdaten angewendet wird.
```{r}
my_first_recipe <- recipe(acceleration~. , data = train_data) %>%
  step_rm(car_name) %>%
  # im Fall einer interaction
  step_interact(terms = ~ horsepower:weight) %>% 
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors(), -all_outcomes())

prepped_recipe <- prep(my_first_recipe, training = train_data)
prepped_test_data<-prep(my_first_recipe,new_data=test_data) %>% juice()

#test_bsp<- prepped_recipe %>% juice()
```

prep(): Vorbereitung (prep) ist der Schritt, bei dem das Rezept auf den Trainingsdaten angewendet wird. Es bereitet die Transformationen vor und extrahiert relevante Informationen, um später auf neuen Daten angewendet zu werden. Dies beinhaltet beispielsweise das Berechnen von Durchschnitts- und Standardabweichungswerten für die Normalisierung.

bake(): Backen (bake) ist der Schritt, bei dem das vorbereitete Rezept auf neuen Daten angewendet wird. Es führt die Transformationen durch, die während der Vorbereitung festgelegt wurden. Das Ergebnis ist der bereinigte und transformierte Datensatz, der für die Modellierung verwendet werden kann.

# 8 Training
```{r}
# Anpassen des Modells
#linear_model <- lm(prepped_recipe, data = train_data)

# alternativ
linear_model_2<- train(my_first_recipe, data = train_data, method = "lm")

```

# 9 Evaluation
```{r}
# Check the performance on the test dataset
#linear_predictions <- predict(linear_model, newdata = test_data)

linear_predictions_2 <- predict(linear_model_2, newdata = test_data)

# Ziel: Testing datensatz : Realenwerte vs. prognostizierten 
Ergebnis_Test_vgl<- linear_predictions_2 %>% 
  as.tibble() %>% 
  bind_cols(test_data) %>% 
  select(c(value,acceleration, everything()))


# Evaluation
linear_rmse <- sqrt(mean((Ergebnis_Test_vgl$value - test_data$acceleration)^2))

cat("Root Mean Squared Error (Linear Regression):", linear_rmse, "\n")
```

# 10 Amelioaration durch Cross Validation
Cross-Validation: um sicherzustellen, dass die Modellleistung auf verschiedenen Teilmengen der Daten konsistent ist.
Ersten Schritte inkludiert Recipe bleiben unverändert
```{r}
# Erstellen Sie eine Trainingssteuerung für Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)  # 5-Fold Cross-Validation

```
Legt fest, dass eine 5-Fold Cross-Validation durchgeführt wird. Das bedeutet, dass der Datensatz in fünf Teile aufgeteilt wird, und das Modell wird fünfmal trainiert und getestet, wobei jedes Mal ein anderer Teil als Testdatensatz verwendet wird. Dies ermöglicht eine bessere Schätzung der Modellleistung, da das Modell auf verschiedenen Teilmengen der Daten evaluiert wird.

```{r}
# Modell anpassen mit Cross-Validation
linear_model_cv <- caret::train(
  my_first_recipe, 
  data = train_data, 
  method = "lm",  # Verwenden Sie das lineare Regressionsmodell
  trControl = ctrl
)

```

```{r}
# Anzeigen der Cross-Validierungsergebnisse
print(linear_model_cv)
```

# 11 Vergleich

Zuerst prognosen mit beiden Modelle durchführen dann Ergebnis vergleichen
```{r}
# Vorhersagen für den Testdatensatz mit beiden Modellen erstellen
predictions_lm <- predict(linear_model_2, newdata = test_data)
predictions_lm_cv <- predict(linear_model_cv, newdata = test_data)

```

```{r}
# Datenrahmen für die Darstellung erstellen
comparison_data <- data.frame(Actual = test_data$acceleration, LM_Predicted = predictions_lm, LM_CV_Predicted = predictions_lm_cv)

# Streudiagramm: Tatsächliche vs. Vorhergesagte Werte für beide Modelle
ggplot(comparison_data, aes(x = Actual, y = LM_Predicted, color = "Lineares Modell")) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed", color = "blue") +
  geom_point(aes(y = LM_CV_Predicted, color = "Lineares Modell mit CV")) +
  geom_smooth(aes(y = LM_CV_Predicted), method = "lm", se = FALSE, linetype = "dashed", color = "red") +
  labs(title = "Vergleich linearer Modelle", x = "Tatsächliche Werte", y = "Vorhergesagte Werte") +
  scale_color_manual(values = c("Lineares Modell" = "blue", "Lineares Modell mit CV" = "red")) +
  theme_minimal()
```
die Punkte für das lineare Modell ohne Kreuzvalidierung (LM) möglicherweise auf der gleichen Position wie die für das lineare Modell mit Kreuzvalidierung (LM mit CV) liegen, was dazu führt, dass sie sich überlagern.

```{r}
# Punkte für das lineare Modell leicht verschieben
comparison_data$Actual_LM <- comparison_data$Actual - 0.02
comparison_data$Actual_LM_CV <- comparison_data$Actual + 0.02

# Streudiagramm: Tatsächliche vs. Vorhergesagte Werte für beide Modelle
ggplot(comparison_data, aes(x = Actual_LM, y = LM_Predicted, color = "Lineares Modell")) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed", color = "blue") +
  geom_point(aes(x = Actual_LM_CV, y = LM_CV_Predicted, color = "Lineares Modell mit CV")) +
  geom_smooth(aes(x = Actual_LM_CV, y = LM_CV_Predicted), method = "lm", se = FALSE, linetype = "dashed", color = "red") +
  labs(title = "Vergleich linearer Modelle", x = "Tatsächliche Werte", y = "Vorhergesagte Werte") +
  scale_color_manual(values = c("Lineares Modell" = "blue", "Lineares Modell mit CV" = "red")) +
  theme_minimal()
```

# Vorstellung: Workflow
Das Prinzip eines Workflows im maschinellen Lernen umfasst eine strukturierte, wiederholbare Reihe von Schritten, die den gesamten Prozess von der Datenvorbereitung bis hin zur Modellierung und Bewertung abdecken. Ein Workflow ist besonders nützlich, um verschiedene Modelle und Datentransformationen zu vergleichen und die Arbeit zu standardisieren, was besonders in produktiven und kollaborativen Umfeldern von Bedeutung ist. Ein gut definierter Workflow kann auch dazu beitragen, Modelle leichter zu verwalten, zu testen und zu verbessern.


Ein Workflow in R (z. B. mit der tidymodels-Bibliothek) besteht aus mehreren Komponenten:


**Datenvorbereitung und Transformation:**
Hier werden alle erforderlichen Transformationen wie das Entfernen von Variablen, Normalisierung der Daten oder die Erstellung von Dummy-Variablen durchgeführt.
Diese Transformationen werden in einem Rezept (recipe) formuliert und durch den Befehl prep() vorbereitet.

**Modellierung:**
Das Modell wird mit den vorbereiteten Daten trainiert. Der Workflow kann leicht mit verschiedenen Modellen und Hyperparametern angepasst werden.
Durch train() können auch Hyperparameter optimiert werden, und es kann Cross-Validation für eine genauere Modellbewertung durchgeführt werden.

**Modellbewertung:**
Das Modell wird mit Testdaten bewertet. Dies erfolgt üblicherweise durch die Berechnung von Metriken wie RMSE (Root Mean Squared Error) oder R² (Bestimmtheitsmaß).

**Wiederholbarkeit und Validierung:**
Workflows bieten eine saubere Trennung zwischen den verschiedenen Schritten, was die Wiederverwendbarkeit und Validierung des Modells mit unterschiedlichen Datensätzen oder Hyperparametern erleichtert.
Cross-Validation wird häufig eingesetzt, um das Modell auf verschiedenen Teilmengen der Daten zu validieren und so die Verlässlichkeit der Modelleinschätzungen zu erhöhen.

```{r}
# Lade alle nötigen Pakete
library(tidymodels)
library(caret)

# 1. Datenvorbereitung
# Erstellen eines Rezepts für die Datenvorbereitung
my_recipe <- recipe( acceleration~ ., data = train_data) %>% 
  step_rm(car_name) %>%  # Entferne car_name
  step_normalize(all_numeric_predictors()) %>%  # Normalisiere numerische Variablen
  step_dummy(all_nominal_predictors(), -all_outcomes())  # Dummy-Variablen für kategoriale Variablen erstellen

# 2. Modellierung (Linear Regression)
linear_model_spec <- linear_reg() %>% 
  set_engine("lm")  # Wir verwenden lineare Regression

# 3. Modelltraining
linear_model_workflow <- workflow() %>% 
  add_recipe(my_recipe) %>%  # Füge das Rezept hinzu
  add_model(linear_model_spec)  # Füge das Modell hinzu

# Trainiere das Modell mit den Trainingsdaten
linear_model_fit <- linear_model_workflow %>% 
  fit(data = train_data)

# 4. Evaluation des Modells
# Vorhersage für den Testdatensatz
linear_predictions <- predict(linear_model_fit, new_data = test_data) %>%
  bind_cols(test_data)

# Berechne den RMSE für das Modell
linear_rmse <- sqrt(mean((linear_predictions$.pred - test_data$acceleration)^2))
cat("Root Mean Squared Error (Linear Regression):", linear_rmse, "\n")

```

# Cross Validation im Workflow integrieren
```{r}
# Cross-Validation Setup
ctrl <- trainControl(method = "cv", number = 5)  # 5-fache Cross-Validation

# Fügen wir den Cross-Validation-Schritt zum Workflow hinzu
linear_model_cv <- caret::train(
  my_recipe, 
  data = train_data, 
  method = "lm", 
  trControl = ctrl  # Cross-Validation anwenden
)

# Ergebnisse der Cross-Validation anzeigen
print(linear_model_cv)

```

```{r}
# Vorhersagen auf dem Testdatensatz mit Cross-Validation-Modell
linear_predictions_cv <- predict(linear_model_cv, newdata = test_data)
# Berechnung von RMSE
cv_rmse <- sqrt(mean((linear_predictions_cv - test_data$acceleration)^2))

cat("Root Mean Squared Error (Cross-Validation Modell):", cv_rmse, "\n")

```
# Trainiertes Modell speichern
```{r}
#library(readr)
write_rds(linear_model_cv,"trained_model/Car_model.rds")
```
# aufrufen und prognose
```{r}
car_model<- read_rds("trained_model/Car_model.rds")

Repredicting_cars <- predict(car_model, newdata = test_data)


```

